{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thrones2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Â© Yuriy Guts, 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using only the raw text of [A Song of Ice and Fire](https://en.wikipedia.org/wiki/A_Song_of_Ice_and_Fire), we'll derive and explore the semantic properties of its words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import glob\n",
    "import logging\n",
    "import multiprocessing\n",
    "import os\n",
    "import pprint\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jarvis/anaconda3/envs/py27/lib/python2.7/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import gensim.models.word2vec as w2v\n",
    "import sklearn.manifold\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set up logging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Download NLTK tokenizer models (only the first time)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jarvis/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jarvis/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load books from files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "book_filenames = sorted(glob.glob(\"/home/jarvis/My projects/Machine Learning/Siraj_Akash/word_vectors_game_of_thrones-LIVE-master/data/*.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found books:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/jarvis/My projects/Machine Learning/Siraj_Akash/word_vectors_game_of_thrones-LIVE-master/data/got1.txt',\n",
       " '/home/jarvis/My projects/Machine Learning/Siraj_Akash/word_vectors_game_of_thrones-LIVE-master/data/got2.txt',\n",
       " '/home/jarvis/My projects/Machine Learning/Siraj_Akash/word_vectors_game_of_thrones-LIVE-master/data/got3.txt',\n",
       " '/home/jarvis/My projects/Machine Learning/Siraj_Akash/word_vectors_game_of_thrones-LIVE-master/data/got4.txt',\n",
       " '/home/jarvis/My projects/Machine Learning/Siraj_Akash/word_vectors_game_of_thrones-LIVE-master/data/got5.txt']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Found books:\")\n",
    "book_filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combine the books into one string**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading '/home/jarvis/My projects/Machine Learning/Siraj_Akash/word_vectors_game_of_thrones-LIVE-master/data/got1.txt'...\n",
      "Corpus is now 1770659 characters long\n",
      "\n",
      "Reading '/home/jarvis/My projects/Machine Learning/Siraj_Akash/word_vectors_game_of_thrones-LIVE-master/data/got2.txt'...\n",
      "Corpus is now 4071041 characters long\n",
      "\n",
      "Reading '/home/jarvis/My projects/Machine Learning/Siraj_Akash/word_vectors_game_of_thrones-LIVE-master/data/got3.txt'...\n",
      "Corpus is now 6391405 characters long\n",
      "\n",
      "Reading '/home/jarvis/My projects/Machine Learning/Siraj_Akash/word_vectors_game_of_thrones-LIVE-master/data/got4.txt'...\n",
      "Corpus is now 8107945 characters long\n",
      "\n",
      "Reading '/home/jarvis/My projects/Machine Learning/Siraj_Akash/word_vectors_game_of_thrones-LIVE-master/data/got5.txt'...\n",
      "Corpus is now 9719485 characters long\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpus_raw = u\"\"\n",
    "for book_filename in book_filenames:\n",
    "    print(\"Reading '{0}'...\".format(book_filename))\n",
    "    with codecs.open(book_filename, \"r\", \"utf-8\") as book_file:\n",
    "        corpus_raw += book_file.read()\n",
    "    print(\"Corpus is now {0} characters long\".format(len(corpus_raw)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split the corpus into sentences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_sentences = tokenizer.tokenize(corpus_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#convert into a list of words\n",
    "#remove unnnecessary characters, split into words, no hyphens\n",
    "#list of words\n",
    "def sentence_to_wordlist(raw):\n",
    "    clean = re.sub(\"[^a-zA-Z]\",\" \", raw)\n",
    "    words = clean.split()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sentence where each word is tokenized\n",
    "sentences = []\n",
    "for raw_sentence in raw_sentences:\n",
    "    if len(raw_sentence) > 0:\n",
    "        sentences.append(sentence_to_wordlist(raw_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heraldic crest by Virginia Norey.\n",
      "[u'Heraldic', u'crest', u'by', u'Virginia', u'Norey']\n"
     ]
    }
   ],
   "source": [
    "print(raw_sentences[5])\n",
    "print(sentence_to_wordlist(raw_sentences[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The book corpus contains 1,818,103 tokens\n"
     ]
    }
   ],
   "source": [
    "token_count = sum([len(sentence) for sentence in sentences])\n",
    "print(\"The book corpus contains {0:,} tokens\".format(token_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ONCE we have vectors\n",
    "#step 3 - build model\n",
    "#3 main tasks that vectors help with\n",
    "#DISTANCE, SIMILARITY, RANKING\n",
    "\n",
    "# Dimensionality of the resulting word vectors.\n",
    "#more dimensions, more computationally expensive to train\n",
    "#but also more accurate\n",
    "#more dimensions = more generalized\n",
    "num_features = 20\n",
    "# Minimum word count threshold.\n",
    "min_word_count = 3\n",
    "\n",
    "# Number of threads to run in parallel.\n",
    "#more workers, faster we train\n",
    "num_workers = multiprocessing.cpu_count()\n",
    "\n",
    "# Context window length.\n",
    "context_size = 7\n",
    "\n",
    "# Downsample setting for frequent words.\n",
    "#0 - 1e-5 is good for this\n",
    "downsampling = 1e-3\n",
    "\n",
    "# Seed for the RNG, to make the results reproducible.\n",
    "#random number generator\n",
    "#deterministic, good for debugging\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thrones2vec = w2v.Word2Vec(\n",
    "    sg=1,\n",
    "    seed=seed,\n",
    "    workers=num_workers,\n",
    "    size=num_features,\n",
    "    min_count=min_word_count,\n",
    "    window=context_size,\n",
    "    sample=downsampling\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-06 18:03:35,436 : INFO : collecting all words and their counts\n",
      "2017-03-06 18:03:35,437 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-03-06 18:03:36,538 : INFO : PROGRESS: at sentence #10000, processed 140984 words, keeping 10280 word types\n",
      "2017-03-06 18:03:36,795 : INFO : PROGRESS: at sentence #20000, processed 279730 words, keeping 13558 word types\n",
      "2017-03-06 18:03:37,124 : INFO : PROGRESS: at sentence #30000, processed 420336 words, keeping 16598 word types\n",
      "2017-03-06 18:03:37,526 : INFO : PROGRESS: at sentence #40000, processed 556581 words, keeping 18324 word types\n",
      "2017-03-06 18:03:37,709 : INFO : PROGRESS: at sentence #50000, processed 686247 words, keeping 19714 word types\n",
      "2017-03-06 18:03:38,160 : INFO : PROGRESS: at sentence #60000, processed 828497 words, keeping 21672 word types\n",
      "2017-03-06 18:03:38,465 : INFO : PROGRESS: at sentence #70000, processed 973830 words, keeping 23093 word types\n",
      "2017-03-06 18:03:38,879 : INFO : PROGRESS: at sentence #80000, processed 1114967 words, keeping 24252 word types\n",
      "2017-03-06 18:03:39,309 : INFO : PROGRESS: at sentence #90000, processed 1260481 words, keeping 26007 word types\n",
      "2017-03-06 18:03:39,546 : INFO : PROGRESS: at sentence #100000, processed 1393203 words, keeping 26884 word types\n",
      "2017-03-06 18:03:39,902 : INFO : PROGRESS: at sentence #110000, processed 1532150 words, keeping 27809 word types\n",
      "2017-03-06 18:03:40,145 : INFO : PROGRESS: at sentence #120000, processed 1680961 words, keeping 28486 word types\n",
      "2017-03-06 18:03:40,371 : INFO : collected 29026 word types from a corpus of 1818103 raw words and 128868 sentences\n",
      "2017-03-06 18:03:40,375 : INFO : Loading a fresh vocabulary\n",
      "2017-03-06 18:03:40,505 : INFO : min_count=3 retains 17277 unique words (59% of original 29026, drops 11749)\n",
      "2017-03-06 18:03:40,507 : INFO : min_count=3 leaves 1802699 word corpus (99% of original 1818103, drops 15404)\n",
      "2017-03-06 18:03:40,595 : INFO : deleting the raw counts dictionary of 29026 items\n",
      "2017-03-06 18:03:40,597 : INFO : sample=0.001 downsamples 50 most-common words\n",
      "2017-03-06 18:03:40,598 : INFO : downsampling leaves estimated 1404424 word corpus (77.9% of prior 1802699)\n",
      "2017-03-06 18:03:40,599 : INFO : estimated required memory for 17277 words and 20 dimensions: 11402820 bytes\n",
      "2017-03-06 18:03:40,787 : INFO : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "thrones2vec.build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-06 18:03:42,301 : WARNING : direct access to vocab will not be supported in future gensim releases, please use model.wv.vocab\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec vocabulary length: 17277\n"
     ]
    }
   ],
   "source": [
    "print(\"Word2Vec vocabulary length:\", len(thrones2vec.vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Start training, this might take a minute or two...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-06 18:03:43,858 : INFO : training model with 4 workers on 17277 vocabulary and 20 features, using sg=1 hs=0 sample=0.001 negative=5 window=7\n",
      "2017-03-06 18:03:43,861 : INFO : expecting 128868 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-03-06 18:03:45,034 : INFO : PROGRESS: at 4.65% examples, 313390 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-06 18:03:46,061 : INFO : PROGRESS: at 8.42% examples, 277446 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-06 18:03:47,088 : INFO : PROGRESS: at 12.45% examples, 280336 words/s, in_qsize 8, out_qsize 0\n",
      "2017-03-06 18:03:48,127 : INFO : PROGRESS: at 17.58% examples, 295602 words/s, in_qsize 8, out_qsize 0\n",
      "2017-03-06 18:03:49,145 : INFO : PROGRESS: at 22.18% examples, 302958 words/s, in_qsize 8, out_qsize 0\n",
      "2017-03-06 18:03:50,152 : INFO : PROGRESS: at 27.43% examples, 311184 words/s, in_qsize 8, out_qsize 0\n",
      "2017-03-06 18:03:51,155 : INFO : PROGRESS: at 32.44% examples, 317275 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-06 18:03:52,160 : INFO : PROGRESS: at 35.69% examples, 305587 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-06 18:03:53,193 : INFO : PROGRESS: at 39.09% examples, 297947 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-06 18:03:54,217 : INFO : PROGRESS: at 42.27% examples, 291009 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-06 18:03:55,215 : INFO : PROGRESS: at 45.63% examples, 285559 words/s, in_qsize 8, out_qsize 0\n",
      "2017-03-06 18:03:56,217 : INFO : PROGRESS: at 49.07% examples, 281028 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-06 18:03:57,251 : INFO : PROGRESS: at 52.31% examples, 276618 words/s, in_qsize 8, out_qsize 0\n",
      "2017-03-06 18:03:58,255 : INFO : PROGRESS: at 55.55% examples, 272811 words/s, in_qsize 8, out_qsize 0\n",
      "2017-03-06 18:03:59,318 : INFO : PROGRESS: at 58.97% examples, 270156 words/s, in_qsize 8, out_qsize 1\n",
      "2017-03-06 18:04:00,330 : INFO : PROGRESS: at 62.15% examples, 267510 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-06 18:04:01,327 : INFO : PROGRESS: at 65.49% examples, 265342 words/s, in_qsize 8, out_qsize 0\n",
      "2017-03-06 18:04:02,363 : INFO : PROGRESS: at 69.06% examples, 263423 words/s, in_qsize 8, out_qsize 0\n",
      "2017-03-06 18:04:03,369 : INFO : PROGRESS: at 72.42% examples, 262135 words/s, in_qsize 8, out_qsize 0\n",
      "2017-03-06 18:04:04,372 : INFO : PROGRESS: at 75.78% examples, 260568 words/s, in_qsize 8, out_qsize 0\n",
      "2017-03-06 18:04:05,375 : INFO : PROGRESS: at 78.97% examples, 259130 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-06 18:04:06,405 : INFO : PROGRESS: at 82.25% examples, 257881 words/s, in_qsize 8, out_qsize 0\n",
      "2017-03-06 18:04:07,422 : INFO : PROGRESS: at 85.72% examples, 256891 words/s, in_qsize 8, out_qsize 0\n",
      "2017-03-06 18:04:08,433 : INFO : PROGRESS: at 89.06% examples, 255450 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-06 18:04:09,454 : INFO : PROGRESS: at 92.30% examples, 254336 words/s, in_qsize 8, out_qsize 0\n",
      "2017-03-06 18:04:10,460 : INFO : PROGRESS: at 95.78% examples, 253687 words/s, in_qsize 8, out_qsize 0\n",
      "2017-03-06 18:04:11,482 : INFO : PROGRESS: at 99.07% examples, 252934 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-06 18:04:11,717 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-03-06 18:04:11,760 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-03-06 18:04:11,761 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-03-06 18:04:11,768 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-03-06 18:04:11,770 : INFO : training on 9090515 raw words (7022758 effective words) took 27.8s, 252916 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7022758"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thrones2vec.train(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save to file, can be useful later**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"trained\"):\n",
    "    os.makedirs(\"trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-06 18:05:47,623 : INFO : saving Word2Vec object under trained/thrones2vec.w2v, separately None\n",
      "2017-03-06 18:05:47,699 : INFO : not storing attribute syn0norm\n",
      "2017-03-06 18:05:47,701 : INFO : not storing attribute cum_table\n",
      "2017-03-06 18:05:54,169 : INFO : saved trained/thrones2vec.w2v\n"
     ]
    }
   ],
   "source": [
    "thrones2vec.save(os.path.join(\"trained\", \"thrones2vec.w2v\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-06 18:05:54,176 : INFO : loading Word2Vec object from trained/thrones2vec.w2v\n",
      "2017-03-06 18:05:54,812 : INFO : loading wv recursively from trained/thrones2vec.w2v.wv.* with mmap=None\n",
      "2017-03-06 18:05:54,813 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-03-06 18:05:54,814 : INFO : setting ignored attribute cum_table to None\n",
      "2017-03-06 18:05:54,815 : INFO : loaded trained/thrones2vec.w2v\n"
     ]
    }
   ],
   "source": [
    "thrones2vec = w2v.Word2Vec.load(os.path.join(\"trained\", \"thrones2vec.w2v\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compress the word vectors into 2D space and plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#my video - how to visualize a dataset easily\n",
    "tsne = sklearn.manifold.TSNE(n_components=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-06 18:06:00,466 : WARNING : direct access to syn0 will not be supported in future gensim releases, please use model.wv.syn0\n"
     ]
    }
   ],
   "source": [
    "all_word_vectors_matrix = thrones2vec.syn0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train t-SNE, this could take a minute or two...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_word_vectors_matrix_2d = tsne.fit_transform(all_word_vectors_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the big picture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "points = pd.DataFrame(\n",
    "    [\n",
    "        (word, coords[0], coords[1])\n",
    "        for word, coords in [\n",
    "            (word, all_word_vectors_matrix_2d[thrones2vec.vocab[word].index])\n",
    "            for word in thrones2vec.vocab\n",
    "        ]\n",
    "    ],\n",
    "    columns=[\"word\", \"x\", \"y\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "points.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "points.plot.scatter(\"x\", \"y\", s=10, figsize=(20, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Zoom in to some interesting places**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_region(x_bounds, y_bounds):\n",
    "    slice = points[\n",
    "        (x_bounds[0] <= points.x) &\n",
    "        (points.x <= x_bounds[1]) & \n",
    "        (y_bounds[0] <= points.y) &\n",
    "        (points.y <= y_bounds[1])\n",
    "    ]\n",
    "    \n",
    "    ax = slice.plot.scatter(\"x\", \"y\", s=35, figsize=(10, 8))\n",
    "    for i, point in slice.iterrows():\n",
    "        ax.text(point.x + 0.005, point.y + 0.005, point.word, fontsize=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**People related to Kingsguard ended up together**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_region(x_bounds=(4.0, 4.2), y_bounds=(-0.5, -0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Food products are grouped nicely as well. Aerys (The Mad King) being close to \"roasted\" also looks sadly correct**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_region(x_bounds=(0, 1), y_bounds=(4, 4.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore semantic similarities between book characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Words closest to the given word**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thrones2vec.most_similar(\"Stark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thrones2vec.most_similar(\"Aerys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thrones2vec.most_similar(\"direwolf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear relationships between word pairs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nearest_similarity_cosmul(start1, end1, end2):\n",
    "    similarities = thrones2vec.most_similar_cosmul(\n",
    "        positive=[end2, start1],\n",
    "        negative=[end1]\n",
    "    )\n",
    "    start2 = similarities[0][0]\n",
    "    print(\"{start1} is related to {end1}, as {start2} is related to {end2}\".format(**locals()))\n",
    "    return start2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nearest_similarity_cosmul(\"Stark\", \"Winterfell\", \"Riverrun\")\n",
    "nearest_similarity_cosmul(\"Jaime\", \"sword\", \"wine\")\n",
    "nearest_similarity_cosmul(\"Arya\", \"Nymeria\", \"dragons\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
